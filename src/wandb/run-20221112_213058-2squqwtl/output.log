11/12/2022 21:30:59 - INFO - __main__ - ----------------------------------------------------------------------------------------------------
11/12/2022 21:30:59 - INFO - __main__ - Cached results:
11/12/2022 21:30:59 - INFO - __main__ - Task #1: VQAv2 - best score = 63.57
11/12/2022 21:30:59 - INFO - __main__ - ----------------------------------------------------------------------------------------------------
11/12/2022 21:30:59 - INFO - __main__ - Training models on Vision-Language continual learning tasks...
11/12/2022 21:30:59 - INFO - __main__ - ----------------------------------------------------------------------------------------------------
11/12/2022 21:30:59 - INFO - __main__ - ********************** found the task token with same task key! *****************************
11/12/2022 21:30:59 - INFO - __main__ - Found checkpoint for task VQAv2!
Creating DyTox!
Traceback (most recent call last):
  File "/project/rostamim_919/caiyulia/Multi-Dytox/src/run.py", line 189, in main
    model.load_state_dict(torch.load(os.path.join(task_output_dir, 'model')))
  File "/home1/caiyulia/.conda/envs/climb/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1483, in load_state_dict
    self.__class__.__name__, "\n\t".join(error_msgs)))
RuntimeError: Error(s) in loading state_dict for DyTox:
	Missing key(s) in state_dict: "transformer.vilt_encoder.vilt.embeddings.cls_token", "transformer.vilt_encoder.vilt.embeddings.position_embeddings", "transformer.vilt_encoder.vilt.embeddings.text_embeddings.position_ids", "transformer.vilt_encoder.vilt.embeddings.text_embeddings.word_embeddings.weight", "transformer.vilt_encoder.vilt.embeddings.text_embeddings.position_embeddings.weight", "transformer.vilt_encoder.vilt.embeddings.text_embeddings.token_type_embeddings.weight", "transformer.vilt_encoder.vilt.embeddings.text_embeddings.LayerNorm.weight", "transformer.vilt_encoder.vilt.embeddings.text_embeddings.LayerNorm.bias", "transformer.vilt_encoder.vilt.embeddings.patch_embeddings.projection.weight", "transformer.vilt_encoder.vilt.embeddings.patch_embeddings.projection.bias", "transformer.vilt_encoder.vilt.embeddings.token_type_embeddings.weight", "transformer.vilt_encoder.vilt.encoder.layer.0.attention.attention.query.weight", "transformer.vilt_encoder.vilt.encoder.layer.0.attention.attention.query.bias", "transformer.vilt_encoder.vilt.encoder.layer.0.attention.attention.key.weight", "transformer.vilt_encoder.vilt.encoder.layer.0.attention.attention.key.bias", "transformer.vilt_encoder.vilt.encoder.layer.0.attention.attention.value.weight", "transformer.vilt_encoder.vilt.encoder.layer.0.attention.attention.value.bias", "transformer.vilt_encoder.vilt.encoder.layer.0.attention.output.dense.weight", "transformer.vilt_encoder.vilt.encoder.layer.0.attention.output.dense.bias", "transformer.vilt_encoder.vilt.encoder.layer.0.intermediate.dense.weight", "transformer.vilt_encoder.vilt.encoder.layer.0.intermediate.dense.bias", "transformer.vilt_encoder.vilt.encoder.layer.0.output.dense.weight", "transformer.vilt_encoder.vilt.encoder.layer.0.output.dense.bias", "transformer.vilt_encoder.vilt.encoder.layer.0.layernorm_before.weight", "transformer.vilt_encoder.vilt.encoder.layer.0.layernorm_before.bias", "transformer.vilt_encoder.vilt.encoder.layer.0.layernorm_after.weight", "transformer.vilt_encoder.vilt.encoder.layer.0.layernorm_after.bias", "transformer.vilt_encoder.vilt.encoder.layer.1.attention.attention.query.weight", "transformer.vilt_encoder.vilt.encoder.layer.1.attention.attention.query.bias", "transformer.vilt_encoder.vilt.encoder.layer.1.attention.attention.key.weight", "transformer.vilt_encoder.vilt.encoder.layer.1.attention.attention.key.bias", "transformer.vilt_encoder.vilt.encoder.layer.1.attention.attention.value.weight", "transformer.vilt_encoder.vilt.encoder.layer.1.attention.attention.value.bias", "transformer.vilt_encoder.vilt.encoder.layer.1.attention.output.dense.weight", "transformer.vilt_encoder.vilt.encoder.layer.1.attention.output.dense.bias", "transformer.vilt_encoder.vilt.encoder.layer.1.intermediate.dense.weight", "transformer.vilt_encoder.vilt.encoder.layer.1.intermediate.dense.bias", "transformer.vilt_encoder.vilt.encoder.layer.1.output.dense.weight", "transformer.vilt_encoder.vilt.encoder.layer.1.output.dense.bias", "transformer.vilt_encoder.vilt.encoder.layer.1.layernorm_before.weight", "transformer.vilt_encoder.vilt.encoder.layer.1.layernorm_before.bias", "transformer.vilt_encoder.vilt.encoder.layer.1.layernorm_after.weight", "transformer.vilt_encoder.vilt.encoder.layer.1.layernorm_after.bias", "transformer.vilt_encoder.vilt.encoder.layer.2.attention.attention.query.weight", "transformer.vilt_encoder.vilt.encoder.layer.2.attention.attention.query.bias", "transformer.vilt_encoder.vilt.encoder.layer.2.attention.attention.key.weight", "transformer.vilt_encoder.vilt.encoder.layer.2.attention.attention.key.bias", "transformer.vilt_encoder.vilt.encoder.layer.2.attention.attention.value.weight", "transformer.vilt_encoder.vilt.encoder.layer.2.attention.attention.value.bias", "transformer.vilt_encoder.vilt.encoder.layer.2.attention.output.dense.weight", "transformer.vilt_encoder.vilt.encoder.layer.2.attention.output.dense.bias", "transformer.vilt_encoder.vilt.encoder.layer.2.intermediate.dense.weight", "transformer.vilt_encoder.vilt.encoder.layer.2.intermediate.dense.bias", "transformer.vilt_encoder.vilt.encoder.layer.2.output.dense.weight", "transformer.vilt_encoder.vilt.encoder.layer.2.output.dense.bias", "transformer.vilt_encoder.vilt.encoder.layer.2.layernorm_before.weight", "transformer.vilt_encoder.vilt.encoder.layer.2.layernorm_before.bias", "transformer.vilt_encoder.vilt.encoder.layer.2.layernorm_after.weight", "transformer.vilt_encoder.vilt.encoder.layer.2.layernorm_after.bias", "transformer.vilt_encoder.vilt.encoder.layer.3.attention.attention.query.weight", "transformer.vilt_encoder.vilt.encoder.layer.3.attention.attention.query.bias", "transformer.vilt_encoder.vilt.encoder.layer.3.attention.attention.key.weight", "transformer.vilt_encoder.vilt.encoder.layer.3.attention.attention.key.bias", "transformer.vilt_encoder.vilt.encoder.layer.3.attention.attention.value.weight", "transformer.vilt_encoder.vilt.encoder.layer.3.attention.attention.value.bias", "transformer.vilt_encoder.vilt.encoder.layer.3.attention.output.dense.weight", "transformer.vilt_encoder.vilt.encoder.layer.3.attention.output.dense.bias", "transformer.vilt_encoder.vilt.encoder.layer.3.intermediate.dense.weight", "transformer.vilt_encoder.vilt.encoder.layer.3.intermediate.dense.bias", "transformer.vilt_encoder.vilt.encoder.layer.3.output.dense.weight", "transformer.vilt_encoder.vilt.encoder.layer.3.output.dense.bias", "transformer.vilt_encoder.vilt.encoder.layer.3.layernorm_before.weight", "transformer.vilt_encoder.vilt.encoder.layer.3.layernorm_before.bias", "transformer.vilt_encoder.vilt.encoder.layer.3.layernorm_after.weight", "transformer.vilt_encoder.vilt.encoder.layer.3.layernorm_after.bias", "transformer.vilt_encoder.vilt.encoder.layer.4.attention.attention.query.weight", "transformer.vilt_encoder.vilt.encoder.layer.4.attention.attention.query.bias", "transformer.vilt_encoder.vilt.encoder.layer.4.attention.attention.key.weight", "transformer.vilt_encoder.vilt.encoder.layer.4.attention.attention.key.bias", "transformer.vilt_encoder.vilt.encoder.layer.4.attention.attention.value.weight", "transformer.vilt_encoder.vilt.encoder.layer.4.attention.attention.value.bias", "transformer.vilt_encoder.vilt.encoder.layer.4.attention.output.dense.weight", "transformer.vilt_encoder.vilt.encoder.layer.4.attention.output.dense.bias", "transformer.vilt_encoder.vilt.encoder.layer.4.intermediate.dense.weight", "transformer.vilt_encoder.vilt.encoder.layer.4.intermediate.dense.bias", "transformer.vilt_encoder.vilt.encoder.layer.4.output.dense.weight", "transformer.vilt_encoder.vilt.encoder.layer.4.output.dense.bias", "transformer.vilt_encoder.vilt.encoder.layer.4.layernorm_before.weight", "transformer.vilt_encoder.vilt.encoder.layer.4.layernorm_before.bias", "transformer.vilt_encoder.vilt.encoder.layer.4.layernorm_after.weight", "transformer.vilt_encoder.vilt.encoder.layer.4.layernorm_after.bias", "transformer.vilt_encoder.vilt.encoder.layer.5.attention.attention.query.weight", "transformer.vilt_encoder.vilt.encoder.layer.5.attention.attention.query.bias", "transformer.vilt_encoder.vilt.encoder.layer.5.attention.attention.key.weight", "transformer.vilt_encoder.vilt.encoder.layer.5.attention.attention.key.bias", "transformer.vilt_encoder.vilt.encoder.layer.5.attention.attention.value.weight", "transformer.vilt_encoder.vilt.encoder.layer.5.attention.attention.value.bias", "transformer.vilt_encoder.vilt.encoder.layer.5.attention.output.dense.weight", "transformer.vilt_encoder.vilt.encoder.layer.5.attention.output.dense.bias", "transformer.vilt_encoder.vilt.encoder.layer.5.intermediate.dense.weight", "transformer.vilt_encoder.vilt.encoder.layer.5.intermediate.dense.bias", "transformer.vilt_encoder.vilt.encoder.layer.5.output.dense.weight", "transformer.vilt_encoder.vilt.encoder.layer.5.output.dense.bias", "transformer.vilt_encoder.vilt.encoder.layer.5.layernorm_before.weight", "transformer.vilt_encoder.vilt.encoder.layer.5.layernorm_before.bias", "transformer.vilt_encoder.vilt.encoder.layer.5.layernorm_after.weight", "transformer.vilt_encoder.vilt.encoder.layer.5.layernorm_after.bias", "transformer.vilt_encoder.vilt.encoder.layer.6.attention.attention.query.weight", "transformer.vilt_encoder.vilt.encoder.layer.6.attention.attention.query.bias", "transformer.vilt_encoder.vilt.encoder.layer.6.attention.attention.key.weight", "transformer.vilt_encoder.vilt.encoder.layer.6.attention.attention.key.bias", "transformer.vilt_encoder.vilt.encoder.layer.6.attention.attention.value.weight", "transformer.vilt_encoder.vilt.encoder.layer.6.attention.attention.value.bias", "transformer.vilt_encoder.vilt.encoder.layer.6.attention.output.dense.weight", "transformer.vilt_encoder.vilt.encoder.layer.6.attention.output.dense.bias", "transformer.vilt_encoder.vilt.encoder.layer.6.intermediate.dense.weight", "transformer.vilt_encoder.vilt.encoder.layer.6.intermediate.dense.bias", "transformer.vilt_encoder.vilt.encoder.layer.6.output.dense.weight", "transformer.vilt_encoder.vilt.encoder.layer.6.output.dense.bias", "transformer.vilt_encoder.vilt.encoder.layer.6.layernorm_before.weight", "transformer.vilt_encoder.vilt.encoder.layer.6.layernorm_before.bias", "transformer.vilt_encoder.vilt.encoder.layer.6.layernorm_after.weight", "transformer.vilt_encoder.vilt.encoder.layer.6.layernorm_after.bias", "transformer.vilt_encoder.vilt.encoder.layer.7.attention.attention.query.weight", "transformer.vilt_encoder.vilt.encoder.layer.7.attention.attention.query.bias", "transformer.vilt_encoder.vilt.encoder.layer.7.attention.attention.key.weight", "transformer.vilt_encoder.vilt.encoder.layer.7.attention.attention.key.bias", "transformer.vilt_encoder.vilt.encoder.layer.7.attention.attention.value.weight", "transformer.vilt_encoder.vilt.encoder.layer.7.attention.attention.value.bias", "transformer.vilt_encoder.vilt.encoder.layer.7.attention.output.dense.weight", "transformer.vilt_encoder.vilt.encoder.layer.7.attention.output.dense.bias", "transformer.vilt_encoder.vilt.encoder.layer.7.intermediate.dense.weight", "transformer.vilt_encoder.vilt.encoder.layer.7.intermediate.dense.bias", "transformer.vilt_encoder.vilt.encoder.layer.7.output.dense.weight", "transformer.vilt_encoder.vilt.encoder.layer.7.output.dense.bias", "transformer.vilt_encoder.vilt.encoder.layer.7.layernorm_before.weight", "transformer.vilt_encoder.vilt.encoder.layer.7.layernorm_before.bias", "transformer.vilt_encoder.vilt.encoder.layer.7.layernorm_after.weight", "transformer.vilt_encoder.vilt.encoder.layer.7.layernorm_after.bias", "transformer.vilt_encoder.vilt.encoder.layer.8.attention.attention.query.weight", "transformer.vilt_encoder.vilt.encoder.layer.8.attention.attention.query.bias", "transformer.vilt_encoder.vilt.encoder.layer.8.attention.attention.key.weight", "transformer.vilt_encoder.vilt.encoder.layer.8.attention.attention.key.bias", "transformer.vilt_encoder.vilt.encoder.layer.8.attention.attention.value.weight", "transformer.vilt_encoder.vilt.encoder.layer.8.attention.attention.value.bias", "transformer.vilt_encoder.vilt.encoder.layer.8.attention.output.dense.weight", "transformer.vilt_encoder.vilt.encoder.layer.8.attention.output.dense.bias", "transformer.vilt_encoder.vilt.encoder.layer.8.intermediate.dense.weight", "transformer.vilt_encoder.vilt.encoder.layer.8.intermediate.dense.bias", "transformer.vilt_encoder.vilt.encoder.layer.8.output.dense.weight", "transformer.vilt_encoder.vilt.encoder.layer.8.output.dense.bias", "transformer.vilt_encoder.vilt.encoder.layer.8.layernorm_before.weight", "transformer.vilt_encoder.vilt.encoder.layer.8.layernorm_before.bias", "transformer.vilt_encoder.vilt.encoder.layer.8.layernorm_after.weight", "transformer.vilt_encoder.vilt.encoder.layer.8.layernorm_after.bias", "transformer.vilt_encoder.vilt.encoder.layer.9.attention.attention.query.weight", "transformer.vilt_encoder.vilt.encode